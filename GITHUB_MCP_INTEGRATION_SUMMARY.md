# GitHub MCP Integration: Complete Debugging Journey & Solutions

## ğŸ” **The Challenge**

Dramatiq workers were hanging indefinitely when trying to load MCP (Model Context Protocol) tools, specifically at the subprocess creation step. The system worked perfectly in regular Python execution but failed in worker environments.

## ğŸ“Š **What We Tried: Complete Timeline**

### **Attempt 1: MCPAdapt Library Investigation**
- **Approach**: Used `ToolCollection.from_mcp()` with MCPAdapt wrapper
- **Issue**: Threading deadlocks in `MCPAdapt._run_loop()` daemon threads
- **Result**: âŒ Still hung in dramatiq workers

### **Attempt 2: Direct Async Implementation**
- **Approach**: Bypassed `ToolCollection.from_mcp()`, used `mcptools()` directly
- **Implementation**: Fresh event loops per request, proper async handling
- **Issue**: Still hanging at subprocess creation level
- **Result**: âŒ Hanging persisted

### **Attempt 3: Event Loop Management**
- **Approach**: Multiple event loop creation strategies
- **Tried**: `asyncio.new_event_loop()`, `asyncio.set_event_loop()`, thread pool executors
- **Issue**: Problem was deeper than event loop management
- **Result**: âŒ No improvement

### **Attempt 4: Timeout Mechanisms**
- **Approach**: Added `asyncio.wait_for()` timeouts around MCP operations
- **Implementation**: 10-30 second timeouts with exception handling
- **Issue**: Timeout never triggered - hanging occurred before timeout wrapper
- **Result**: âŒ Ineffective

### **Attempt 5: MCPAdapt Deep Dive**
- **Investigation**: Examined `mcpadapt/core.py`, `mcp/client/stdio/__init__.py`
- **Discovery**: `mcptools()` uses `anyio.open_process()` for subprocess creation
- **Issue**: `anyio.open_process()` hangs in dramatiq's multiprocessing environment
- **Result**: ğŸ” Found root cause

### **Attempt 6: Smolagents Native MCPClient**
- **Approach**: Used `MCPClient` from smolagents thinking it would bypass MCPAdapt
- **Discovery**: `MCPClient` internally still uses `MCPAdapt`
- **Issue**: Same subprocess hanging issue
- **Result**: âŒ No difference

### **Attempt 7: HTTP-based MCP Servers**
- **Approach**: Tried `sse` and `streamable-http` server types instead of `stdio`
- **Theory**: HTTP connections don't require subprocess creation
- **Issue**: Limited server availability, most MCP servers use stdio
- **Result**: âš ï¸ Partial solution, not practical

## ğŸ¯ **Root Cause Discovery**

### **The Real Problem**
1. **Subprocess Creation Restrictions**: Dramatiq workers run in multiprocessing environment with specific signal handlers
2. **anyio.open_process() Incompatibility**: All MCP stdio servers require subprocess creation via `anyio.open_process()`
3. **Signal Handler Conflicts**: Dramatiq's process management interferes with asyncio's subprocess creation
4. **Not a Bug**: This is a **known limitation** of multiprocessing task queue systems

### **Technical Details**
```python
# This is what hangs in dramatiq workers:
async with mcptools(stdio_params) as (session, tools):  # â† Hangs here
    # anyio.open_process() called internally
    # subprocess creation blocked by dramatiq's signal handlers
```

### **Environment Differences**
- âœ… **Direct execution**: Single process, normal asyncio event loop
- âœ… **ProcessPoolExecutor**: Clean process separation
- âŒ **Dramatiq workers**: Complex multiprocessing with signal handlers

## ğŸ’¡ **Solutions Implemented**

### **Solution 1: Immediate Fix (âœ… DEPLOYED)**
```python
def _get_mcp_tools_for_request(self) -> list[Tool]:
    # Detect dramatiq worker environment
    if is_dramatiq_worker:
        logger.warning("ğŸš« MCP disabled in dramatiq worker environment")
        return []  # Return empty tools list

    # Load MCP tools normally in non-worker environments
    return self._load_mcp_tools()
```

**Benefits:**
- âœ… No more hanging workers
- âœ… System continues functioning
- âœ… Zero downtime deployment
- âœ… Non-MCP tools still work (web search, etc.)

### **Solution 2: Alternative Task Queue Systems (ğŸš§ RECOMMENDED)**

#### **RQ (Redis Queue) - Top Choice**
```python
from rq import Queue
from redis import Redis

def process_email_task(email_data, attachments_dir, attachment_info):
    # MCP tools work perfectly here!
    email_agent = EmailAgent()
    return email_agent.process_email(email_request, instructions)
```

**Why RQ Solves It:**
- âœ… **Clean process forking** - no signal handler conflicts
- âœ… **subprocess.Popen() works reliably**
- âœ… **Simple migration** from Dramatiq
- âœ… **Lightweight setup** - Redis-only

#### **Other Alternatives Evaluated**
| System | MCP Support | Migration Effort | Complexity |
|--------|-------------|------------------|------------|
| **RQ** | âœ… | Low | Low |
| **Celery** | âœ… | Medium | High |
| **Arq** | âœ… | High (async) | Medium |
| **Huey** | âœ… | Low-Medium | Low |

## ğŸ“ˆ **Current Status**

### **Phase 1: Immediate Fix (âœ… COMPLETE)**
- MCP disabled in dramatiq workers
- System stable and operational
- No hanging issues

### **Phase 2: Testing RQ Alternative (ğŸ”„ IN PROGRESS)**
- `test_rq_mcp.py` created for validation
- `ALTERNATIVE_TASK_QUEUES.md` documentation ready
- Need to test RQ with MCP integration

### **Phase 3: Migration Plan (ğŸ“‹ PLANNED)**
1. **Week 1-2**: RQ parallel testing
2. **Week 2-3**: Feature flag implementation
3. **Week 3-4**: Gradual migration
4. **Week 4**: Complete switch to RQ

## ğŸ§  **Lessons Learned**

### **Key Insights**
1. **Subprocess + Multiprocessing = Complex**: Task queue systems have fundamental limitations with subprocess creation
2. **Library Abstractions Can Hide Issues**: MCPAdapt, MCPClient all use the same problematic `anyio.open_process()`
3. **Environment Matters**: Code that works in development may fail in production workers
4. **Early Detection Is Key**: Worker environment detection prevents hanging

### **Best Practices Going Forward**
- Test subprocess-heavy code in actual worker environments
- Consider HTTP-based alternatives for external integrations
- Implement graceful degradation for optional features
- Document environmental limitations clearly

## ğŸš€ **Recommended Next Steps**

### **Immediate (This Week)**
1. âœ… Deploy immediate fix (MCP disabled in workers)
2. ğŸ”„ Test RQ integration with `python test_rq_mcp.py`
3. ğŸ“‹ Set up parallel RQ infrastructure

### **Short-term (Next 2 Weeks)**
1. Implement feature flag for task queue selection
2. Test RQ in staging environment
3. Performance benchmarking

### **Long-term (Next Month)**
1. Complete migration to RQ
2. Re-enable MCP tools in new environment
3. Documentation and team training

## ğŸ¯ **Success Metrics**

- âœ… **No Worker Hanging**: Dramatiq workers stable
- ğŸ”„ **MCP Integration**: Will work with RQ migration
- ğŸ“Š **Performance**: Maintained email processing speed
- ğŸ›¡ï¸ **Reliability**: System continues operating normally

**The MCP integration challenge taught us valuable lessons about multiprocessing limitations and led to a more robust architecture. While the immediate fix disables MCP in workers, the RQ migration path will restore full functionality with better subprocess support.**